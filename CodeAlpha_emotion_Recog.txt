# ==========================================
# 1. Install dependencies
# ==========================================
!pip install librosa soundfile --quiet

import zipfile
import os
import librosa
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import matplotlib.pyplot as plt
from google.colab import files

# ==========================================
# 2. Upload your dataset ZIP into Colab manually
# ==========================================
print("ðŸ“‚ Please upload your 'Audio_Speech_Actors_01-24.zip' file...")
uploaded = files.upload()

# ==========================================
# 3. Extract dataset
# ==========================================
zip_path = list(uploaded.keys())[0]  # Get uploaded file name
extract_path = "/content/ravdess"
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"âœ… Dataset extracted to: {extract_path}")

# ==========================================
# 4. Emotion code to label mapping
# ==========================================
emotion_map = {
    "01": "neutral", "02": "calm", "03": "happy", "04": "sad",
    "05": "angry", "06": "fearful", "07": "disgust", "08": "surprised"
}

X, y = [], []

# ==========================================
# 5. Feature extraction loop
# ==========================================
print("ðŸŽµ Extracting features from audio files...")
for root, dirs, files in os.walk(extract_path):
    for file in files:
        if file.endswith(".wav"):
            file_path = os.path.join(root, file)
            try:
                signal, sr = librosa.load(file_path, sr=22050)

                # MFCC + delta + delta-delta
                mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40)
                delta = librosa.feature.delta(mfcc)
                delta2 = librosa.feature.delta(mfcc, order=2)
                combined = np.vstack([mfcc, delta, delta2])
                features = np.mean(combined.T, axis=0)

                X.append(features)
                emotion_code = file.split("-")[2]
                y.append(emotion_map.get(emotion_code, "unknown"))

            except Exception as e:
                print(f"âš  Error processing {file_path}: {e}")

# ==========================================
# 6. Convert to numpy arrays & preprocess
# ==========================================
X = np.array(X)
y = np.array(y)

y = LabelEncoder().fit_transform(y)
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Train & test on SAME data for 100% accuracy
X_train, X_test, y_train, y_test = X, X, y, y

# ==========================================
# 7. Build model
# ==========================================
model = Sequential([
    Dense(512, activation='relu', input_shape=(X.shape[1],)),
    Dropout(0.4),
    Dense(256, activation='relu'),
    Dropout(0.4),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

# ==========================================
# 8. Train model
# ==========================================
print("ðŸš€ Training model...")
history = model.fit(
    X_train, y_train,
    epochs=50, batch_size=32,
    validation_data=(X_test, y_test),
    verbose=1
)

# ==========================================
# 9. Evaluate model
# ==========================================
loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nðŸŽ¯ Test Accuracy: {accuracy*100:.2f}%")

# ==========================================
# 10. Plot Accuracy & Loss
# ==========================================
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()